{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "I need apply \"Arcface\" to face recognize for save good quality image without saving duplicate. can you update my current code or create new file if needed, give me the code according to my folder structure\n",
    "\n",
    "This is my current implementation\n",
    "\n",
    "\"I\n",
    "Bellow I will show my already implemented code. \n",
    "\n",
    "I need Python implimentation to apply these technologies and continue with my already implemented code\n",
    "\n",
    "âœ… Step 1: Detect faces with YOLO-Face \n",
    "âœ… Step 2: Face Recognition with ArcFace\n",
    "âœ… Step 3: If no face, apply background removal MODNet.\n",
    "âœ… Step 4: Extract upper body feature embeddings using OSNet.\n",
    "âœ… Step 5: Store face + body embeddings in FAISS for hybrid matching.\n",
    "\"\n",
    "\n",
    " Give me code whitch creating new file or updating my current code, I need better code according my folder structure \n",
    "\n",
    "This is my current implimented code \n",
    "\n",
    "\"\"\n",
    "\n",
    "\"run_detection.py --> \n",
    "\n",
    "from src.Human_Tracking.pipeline.process_video import process_video\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    camera_ip = \"rtsp://admin:Think22wise@192.168.15.31/video\"  # Change for different sources\n",
    "    process_video(camera_ip)\n",
    "\n",
    "\n",
    "process_video.py -->\n",
    "\n",
    "import cv2\n",
    "import time\n",
    "from src.Human_Tracking.models.yolo_face import FaceDetector\n",
    "from src.Human_Tracking.utils.video_processing import resize_frame\n",
    "from src.Human_Tracking.utils.face_saving import save_face\n",
    "from src.Human_Tracking.utils.image_quality import calculate_quality_score\n",
    "\n",
    "def process_video(camera_ip, min_quality_score=0.70, quality_improvement_threshold=0.10, expansion_factor=0.8):\n",
    "    \"\"\"\n",
    "    Process video stream to detect and save high-quality face images\n",
    "    \n",
    "    Args:\n",
    "        camera_ip (str): Camera URL or device index\n",
    "        min_quality_score (float): Minimum quality threshold (0-1)\n",
    "        quality_improvement_threshold (float): Minimum improvement needed over previous best quality image\n",
    "        expansion_factor (float): How much to expand bounding boxes (0-1)\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(camera_ip)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"âŒ Error opening video source: {camera_ip}\")\n",
    "        return\n",
    "\n",
    "    face_detector = FaceDetector()\n",
    "    previous_faces = {}  # Stores the best quality face per unique ID\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"âš ï¸ Frame read error or stream ended\")\n",
    "            break\n",
    "\n",
    "        frame = resize_frame(frame, scale_percent=80)  # Resize for faster processing\n",
    "\n",
    "        # Detect Faces\n",
    "        results_face = face_detector.detect(frame)\n",
    "\n",
    "        # Process detected faces\n",
    "        timestamp = time.time()\n",
    "        for result in results_face:\n",
    "            for box, confidence in zip(result.boxes.xyxy.cpu().numpy(), result.boxes.conf.cpu().numpy()):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                face_key = tuple(map(int, box))  # Unique face identifier\n",
    "                \n",
    "                # Calculate quality score\n",
    "                quality_score = calculate_quality_score(frame, box)\n",
    "\n",
    "                # Check if this is the best quality image so far\n",
    "                if face_key not in previous_faces:\n",
    "                    previous_faces[face_key] = {'quality_score': quality_score, 'saved_path': None}\n",
    "\n",
    "                prev_quality = previous_faces[face_key]['quality_score']\n",
    "\n",
    "                # Save only if quality is significantly better (improvement_threshold)\n",
    "                if quality_score >= min_quality_score and (previous_faces[face_key]['saved_path'] is None or quality_score > previous_faces[face_key]['quality_score'] + quality_improvement_threshold):\n",
    "\n",
    "                \n",
    "                    # Expand bounding box\n",
    "                    box_width = x2 - x1\n",
    "                    box_height = y2 - y1\n",
    "                    expand_x = int(box_width * expansion_factor)\n",
    "                    expand_y = int(box_height * expansion_factor)\n",
    "\n",
    "                    x1 = max(0, x1 - expand_x)\n",
    "                    y1 = max(0, y1 - expand_y)\n",
    "                    x2 = min(frame.shape[1], x2 + expand_x)\n",
    "                    y2 = min(frame.shape[0], y2 + expand_y)\n",
    "\n",
    "                    expanded_box = (x1, y1, x2, y2)\n",
    "\n",
    "                    # Save the new best-quality face\n",
    "                    saved_path = save_face(frame, expanded_box)\n",
    "\n",
    "                    if saved_path:\n",
    "                        previous_faces[face_key] = {\n",
    "                            'quality_score': quality_score,  \n",
    "                            'saved_path': saved_path\n",
    "                        }\n",
    "                        print(f\"âœ… Saved face (Q:{quality_score:.2f} Q:{prev_quality + quality_improvement_threshold:.2f} C:{confidence:.2f}): {saved_path}\")\n",
    "                    else:\n",
    "                        print(f\"âš ï¸ Failed to save face (Q:{quality_score:.2f})\")\n",
    "                else:\n",
    "                    print(f\"â­ï¸ Skipping face (Q:{quality_score:.2f}), not a significant improvement (prev: {prev_quality:.2f})\")\n",
    "\n",
    "        # Show detection results\n",
    "        cv2.imshow(\"Face Detection\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"ðŸ›‘ Processing stopped\")\n",
    "\n",
    "face_saving.py -- >\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_quality_score(face_image, box=None):\n",
    "    \"\"\"\n",
    "    Calculate quality score - can accept either cropped face or full frame + box\n",
    "    \"\"\"\n",
    "    # If box is provided, extract face from frame first\n",
    "    if box is not None:\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        face_image = face_image[y1:y2, x1:x2]\n",
    "    \n",
    "    if face_image.size == 0 or face_image.shape[0] < 10 or face_image.shape[1] < 10:\n",
    "        return 0\n",
    "        \n",
    "    gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Sharpness (Laplacian variance)\n",
    "    sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    sharpness_score = np.clip(sharpness / 300, 0, 1)\n",
    "    \n",
    "    # Brightness (avoid too dark/bright)\n",
    "    brightness = np.mean(gray)\n",
    "    brightness_score = 1 - abs(brightness - 127) / 127\n",
    "    \n",
    "    # Contrast score\n",
    "    contrast_score = np.std(gray) / 100\n",
    "    \n",
    "    # Combined score\n",
    "    quality_score = (sharpness_score * 0.5 + \n",
    "                    brightness_score * 0.3 + \n",
    "                    contrast_score * 0.2)\n",
    "    \n",
    "    return np.clip(quality_score, 0, 1)\n",
    "\n",
    "def is_high_quality(frame, box, min_score=0.68):\n",
    "    \"\"\"Check if face meets quality threshold\"\"\"\n",
    "    quality_score = calculate_quality_score(frame, box)\n",
    "    return quality_score >= min_scoreSAVE_DIR = \"data/processed/faces\"\n",
    "\n",
    "def save_face(frame, box, timestamp, confidence):\n",
    "    \"\"\"\n",
    "    Saves the best quality face image to the designated directory.\n",
    "    \n",
    "    Args:\n",
    "        frame (numpy array): Original frame.\n",
    "        box (tuple): (x1, y1, x2, y2) coordinates of the face.\n",
    "        timestamp (float): Current timestamp.\n",
    "        confidence (float): Confidence score of detection.\n",
    "    \n",
    "    Returns:\n",
    "        str: Saved image path.\n",
    "    \"\"\"\n",
    "    os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "    x1, y1, x2, y2 = map(int, box)\n",
    "    face_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "    # Save the image\n",
    "    filename = f\"{SAVE_DIR}/face_{int(timestamp)}_{int(confidence * 100)}.png\"\n",
    "    cv2.imwrite(filename, face_crop)\n",
    "\n",
    "    return filename\n",
    "\n",
    "\n",
    "image_quality.py -->\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def calculate_quality_score(face_image, box=None):\n",
    "    \"\"\"\n",
    "    Calculate quality score - can accept either cropped face or full frame + box\n",
    "    \"\"\"\n",
    "    # If box is provided, extract face from frame first\n",
    "    if box is not None:\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        face_image = face_image[y1:y2, x1:x2]\n",
    "    \n",
    "    if face_image.size == 0 or face_image.shape[0] < 10 or face_image.shape[1] < 10:\n",
    "        return 0\n",
    "        \n",
    "    gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Sharpness (Laplacian variance)\n",
    "    sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()\n",
    "    sharpness_score = np.clip(sharpness / 300, 0, 1)\n",
    "    \n",
    "    # Brightness (avoid too dark/bright)\n",
    "    brightness = np.mean(gray)\n",
    "    brightness_score = 1 - abs(brightness - 127) / 127\n",
    "    \n",
    "    # Contrast score\n",
    "    contrast_score = np.std(gray) / 100\n",
    "    \n",
    "    # Combined score\n",
    "    quality_score = (sharpness_score * 0.5 + \n",
    "                    brightness_score * 0.3 + \n",
    "                    contrast_score * 0.2)\n",
    "    \n",
    "    return np.clip(quality_score, 0, 1)\n",
    "\n",
    "def is_high_quality(frame, box, min_score=0.68):\n",
    "    \"\"\"Check if face meets quality threshold\"\"\"\n",
    "    quality_score = calculate_quality_score(frame, box)\n",
    "    return quality_score >= min_score\n",
    "\n",
    "video_processing.py-->\n",
    "\n",
    "import cv2\n",
    "\n",
    "def resize_frame(frame, scale_percent=80):\n",
    "    width = int(frame.shape[1] * scale_percent / 100)\n",
    "    height = int(frame.shape[0] * scale_percent / 100)\n",
    "    return cv2.resize(frame, (width, height))\n",
    "\n",
    "visualization.py -->\n",
    "\n",
    "import cv2\n",
    "\n",
    "def draw_boxes(frame, results, color=(0, 255, 0), label=\"Object\"):\n",
    "    for result in results:\n",
    "        for box, confidence in zip(result.boxes.xyxy.cpu().numpy(), result.boxes.conf.cpu().numpy()):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "            label_text = f\"{label} {confidence:.2f}\"\n",
    "            cv2.putText(frame, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "            \n",
    "    return frame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This is my folder structure\n",
    "\n",
    "HTRACKING/\n",
    "â”œâ”€â”€ .github/\n",
    "â”œâ”€â”€ checkpoints/\n",
    "â”‚   â””â”€â”€ saved_model/\n",
    "â”‚       â”œâ”€â”€ face_yolov8n.pt\n",
    "â”‚       â””â”€â”€ yolov8s.pt\n",
    "â”œâ”€â”€ config/\n",
    "â”œâ”€â”€ configs/\n",
    "â”œâ”€â”€ data/\n",
    "â”‚   â”œâ”€â”€ external/\n",
    "â”‚   â”œâ”€â”€ interim/\n",
    "â”‚   â”œâ”€â”€ processed/\n",
    "â”‚   â””â”€â”€ raw/\n",
    "â”œâ”€â”€ README.md\n",
    "â”œâ”€â”€ deployment/\n",
    "â”œâ”€â”€ docs/\n",
    "â”œâ”€â”€ experiments/\n",
    "â”œâ”€â”€ logs/\n",
    "â”œâ”€â”€ mlruns/\n",
    "â”œâ”€â”€ monitoring/\n",
    "â”œâ”€â”€ notebooks/\n",
    "â”œâ”€â”€ research/\n",
    "â”œâ”€â”€ scripts/\n",
    "â”‚   â”œâ”€â”€ data_pipeline.py\n",
    "â”‚   â”œâ”€â”€ evaluate.py\n",
    "â”‚   â”œâ”€â”€ predict.py\n",
    "â”‚   â”œâ”€â”€ run_detection.py\n",
    "â”‚   â””â”€â”€ train.py\n",
    "â”œâ”€â”€ src/\n",
    "â”‚   â””â”€â”€ Human_Tracking/\n",
    "â”‚       â”œâ”€â”€ __pycache__/\n",
    "â”‚       â”œâ”€â”€ constants/\n",
    "â”‚       â”œâ”€â”€ data/\n",
    "â”‚       â”œâ”€â”€ entity/\n",
    "â”‚       â”œâ”€â”€ features/\n",
    "â”‚       â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚       â”‚   â””â”€â”€ face_tracking.py\n",
    "â”‚       â”œâ”€â”€ inference/\n",
    "â”‚       â”œâ”€â”€ models/\n",
    "â”‚       â”œâ”€â”€ pipeline/\n",
    "â”‚       â”‚   â”œâ”€â”€ __pycache__/\n",
    "â”‚       â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚       â”‚   â””â”€â”€ process_video.py\n",
    "â”‚       â”œâ”€â”€ utils/\n",
    "â”‚       â”‚   â”œâ”€â”€ __pycache__/\n",
    "â”‚       â”‚   â”œâ”€â”€ __init__.py\n",
    "â”‚       â”‚   â”œâ”€â”€ common.py\n",
    "â”‚       â”‚   â”œâ”€â”€ face_saving.py\n",
    "â”‚       â”‚   â”œâ”€â”€ image_quality.py\n",
    "â”‚       â”‚   â”œâ”€â”€ video_processing.py\n",
    "â”‚       â”‚   â””â”€â”€ visualization.py\n",
    "â”‚       â”œâ”€â”€ visualization/\n",
    "â”‚       â””â”€â”€ __init__.py\n",
    "â”œâ”€â”€ tests/\n",
    "â”œâ”€â”€ .gitignore\n",
    "â”œâ”€â”€ app.py\n",
    "â””â”€â”€ Dockerfile\"\"\"\n",
    "\"\n",
    "\n",
    "\" "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
