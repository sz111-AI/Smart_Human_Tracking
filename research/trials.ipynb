I need apply "Arcface" to face recognize for save good quality image without saving duplicate. can you update my current code or create new file if needed, give me the code according to my folder structure

This is my current implementation

"I
Bellow I will show my already implemented code. 

I need Python implimentation to apply these technologies and continue with my already implemented code

âœ… Step 1: Detect faces with YOLO-Face 
âœ… Step 2: Face Recognition with ArcFace
âœ… Step 3: If no face, apply background removal MODNet.
âœ… Step 4: Extract upper body feature embeddings using OSNet.
âœ… Step 5: Store face + body embeddings in FAISS for hybrid matching.
"

 Give me code whitch creating new file or updating my current code, I need better code according my folder structure 

This is my current implimented code 

""

"run_detection.py --> 

from src.Human_Tracking.pipeline.process_video import process_video

if __name__ == "__main__":
    camera_ip = "rtsp://admin:Think22wise@192.168.15.31/video"  # Change for different sources
    process_video(camera_ip)


process_video.py -->

import cv2
import time
from src.Human_Tracking.models.yolo_face import FaceDetector
from src.Human_Tracking.utils.video_processing import resize_frame
from src.Human_Tracking.utils.face_saving import save_face
from src.Human_Tracking.utils.image_quality import calculate_quality_score

def process_video(camera_ip, min_quality_score=0.70, quality_improvement_threshold=0.10, expansion_factor=0.8):
    """
    Process video stream to detect and save high-quality face images
    
    Args:
        camera_ip (str): Camera URL or device index
        min_quality_score (float): Minimum quality threshold (0-1)
        quality_improvement_threshold (float): Minimum improvement needed over previous best quality image
        expansion_factor (float): How much to expand bounding boxes (0-1)
    """
    cap = cv2.VideoCapture(camera_ip)
    if not cap.isOpened():
        print(f"âŒ Error opening video source: {camera_ip}")
        return

    face_detector = FaceDetector()
    previous_faces = {}  # Stores the best quality face per unique ID

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            print("âš ï¸ Frame read error or stream ended")
            break

        frame = resize_frame(frame, scale_percent=80)  # Resize for faster processing

        # Detect Faces
        results_face = face_detector.detect(frame)

        # Process detected faces
        timestamp = time.time()
        for result in results_face:
            for box, confidence in zip(result.boxes.xyxy.cpu().numpy(), result.boxes.conf.cpu().numpy()):
                x1, y1, x2, y2 = map(int, box)
                face_key = tuple(map(int, box))  # Unique face identifier
                
                # Calculate quality score
                quality_score = calculate_quality_score(frame, box)

                # Check if this is the best quality image so far
                if face_key not in previous_faces:
                    previous_faces[face_key] = {'quality_score': quality_score, 'saved_path': None}

                prev_quality = previous_faces[face_key]['quality_score']

                # Save only if quality is significantly better (improvement_threshold)
                if quality_score >= min_quality_score and (previous_faces[face_key]['saved_path'] is None or quality_score > previous_faces[face_key]['quality_score'] + quality_improvement_threshold):

                
                    # Expand bounding box
                    box_width = x2 - x1
                    box_height = y2 - y1
                    expand_x = int(box_width * expansion_factor)
                    expand_y = int(box_height * expansion_factor)

                    x1 = max(0, x1 - expand_x)
                    y1 = max(0, y1 - expand_y)
                    x2 = min(frame.shape[1], x2 + expand_x)
                    y2 = min(frame.shape[0], y2 + expand_y)

                    expanded_box = (x1, y1, x2, y2)

                    # Save the new best-quality face
                    saved_path = save_face(frame, expanded_box)

                    if saved_path:
                        previous_faces[face_key] = {
                            'quality_score': quality_score,  
                            'saved_path': saved_path
                        }
                        print(f"âœ… Saved face (Q:{quality_score:.2f} Q:{prev_quality + quality_improvement_threshold:.2f} C:{confidence:.2f}): {saved_path}")
                    else:
                        print(f"âš ï¸ Failed to save face (Q:{quality_score:.2f})")
                else:
                    print(f"â­ï¸ Skipping face (Q:{quality_score:.2f}), not a significant improvement (prev: {prev_quality:.2f})")

        # Show detection results
        cv2.imshow("Face Detection", frame)
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()
    print("ðŸ›‘ Processing stopped")

face_saving.py -- >

import cv2
import os
import cv2
import numpy as np

def calculate_quality_score(face_image, box=None):
    """
    Calculate quality score - can accept either cropped face or full frame + box
    """
    # If box is provided, extract face from frame first
    if box is not None:
        x1, y1, x2, y2 = map(int, box)
        face_image = face_image[y1:y2, x1:x2]
    
    if face_image.size == 0 or face_image.shape[0] < 10 or face_image.shape[1] < 10:
        return 0
        
    gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
    
    # Sharpness (Laplacian variance)
    sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
    sharpness_score = np.clip(sharpness / 300, 0, 1)
    
    # Brightness (avoid too dark/bright)
    brightness = np.mean(gray)
    brightness_score = 1 - abs(brightness - 127) / 127
    
    # Contrast score
    contrast_score = np.std(gray) / 100
    
    # Combined score
    quality_score = (sharpness_score * 0.5 + 
                    brightness_score * 0.3 + 
                    contrast_score * 0.2)
    
    return np.clip(quality_score, 0, 1)

def is_high_quality(frame, box, min_score=0.68):
    """Check if face meets quality threshold"""
    quality_score = calculate_quality_score(frame, box)
    return quality_score >= min_scoreSAVE_DIR = "data/processed/faces"

def save_face(frame, box, timestamp, confidence):
    """
    Saves the best quality face image to the designated directory.
    
    Args:
        frame (numpy array): Original frame.
        box (tuple): (x1, y1, x2, y2) coordinates of the face.
        timestamp (float): Current timestamp.
        confidence (float): Confidence score of detection.
    
    Returns:
        str: Saved image path.
    """
    os.makedirs(SAVE_DIR, exist_ok=True)

    x1, y1, x2, y2 = map(int, box)
    face_crop = frame[y1:y2, x1:x2]

    # Save the image
    filename = f"{SAVE_DIR}/face_{int(timestamp)}_{int(confidence * 100)}.png"
    cv2.imwrite(filename, face_crop)

    return filename


image_quality.py -->

import cv2
import numpy as np

def calculate_quality_score(face_image, box=None):
    """
    Calculate quality score - can accept either cropped face or full frame + box
    """
    # If box is provided, extract face from frame first
    if box is not None:
        x1, y1, x2, y2 = map(int, box)
        face_image = face_image[y1:y2, x1:x2]
    
    if face_image.size == 0 or face_image.shape[0] < 10 or face_image.shape[1] < 10:
        return 0
        
    gray = cv2.cvtColor(face_image, cv2.COLOR_BGR2GRAY)
    
    # Sharpness (Laplacian variance)
    sharpness = cv2.Laplacian(gray, cv2.CV_64F).var()
    sharpness_score = np.clip(sharpness / 300, 0, 1)
    
    # Brightness (avoid too dark/bright)
    brightness = np.mean(gray)
    brightness_score = 1 - abs(brightness - 127) / 127
    
    # Contrast score
    contrast_score = np.std(gray) / 100
    
    # Combined score
    quality_score = (sharpness_score * 0.5 + 
                    brightness_score * 0.3 + 
                    contrast_score * 0.2)
    
    return np.clip(quality_score, 0, 1)

def is_high_quality(frame, box, min_score=0.68):
    """Check if face meets quality threshold"""
    quality_score = calculate_quality_score(frame, box)
    return quality_score >= min_score

video_processing.py-->

import cv2

def resize_frame(frame, scale_percent=80):
    width = int(frame.shape[1] * scale_percent / 100)
    height = int(frame.shape[0] * scale_percent / 100)
    return cv2.resize(frame, (width, height))

visualization.py -->

import cv2

def draw_boxes(frame, results, color=(0, 255, 0), label="Object"):
    for result in results:
        for box, confidence in zip(result.boxes.xyxy.cpu().numpy(), result.boxes.conf.cpu().numpy()):
            x1, y1, x2, y2 = map(int, box)
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            label_text = f"{label} {confidence:.2f}"
            cv2.putText(frame, label_text, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)
            
    return frame





This is my folder structure

HTRACKING/
â”œâ”€â”€ .github/
â”œâ”€â”€ checkpoints/
â”‚   â””â”€â”€ saved_model/
â”‚       â”œâ”€â”€ face_yolov8n.pt
â”‚       â””â”€â”€ yolov8s.pt
â”œâ”€â”€ config/
â”œâ”€â”€ configs/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ external/
â”‚   â”œâ”€â”€ interim/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ raw/
â”œâ”€â”€ README.md
â”œâ”€â”€ deployment/
â”œâ”€â”€ docs/
â”œâ”€â”€ experiments/
â”œâ”€â”€ logs/
â”œâ”€â”€ mlruns/
â”œâ”€â”€ monitoring/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ research/
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ data_pipeline.py
â”‚   â”œâ”€â”€ evaluate.py
â”‚   â”œâ”€â”€ predict.py
â”‚   â”œâ”€â”€ run_detection.py
â”‚   â””â”€â”€ train.py
â”œâ”€â”€ src/
â”‚   â””â”€â”€ Human_Tracking/
â”‚       â”œâ”€â”€ __pycache__/
â”‚       â”œâ”€â”€ constants/
â”‚       â”œâ”€â”€ data/
â”‚       â”œâ”€â”€ entity/
â”‚       â”œâ”€â”€ features/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ face_tracking.py
â”‚       â”œâ”€â”€ inference/
â”‚       â”œâ”€â”€ models/
â”‚       â”œâ”€â”€ pipeline/
â”‚       â”‚   â”œâ”€â”€ __pycache__/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â””â”€â”€ process_video.py
â”‚       â”œâ”€â”€ utils/
â”‚       â”‚   â”œâ”€â”€ __pycache__/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ common.py
â”‚       â”‚   â”œâ”€â”€ face_saving.py
â”‚       â”‚   â”œâ”€â”€ image_quality.py
â”‚       â”‚   â”œâ”€â”€ video_processing.py
â”‚       â”‚   â””â”€â”€ visualization.py
â”‚       â”œâ”€â”€ visualization/
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ tests/
â”œâ”€â”€ .gitignore
â”œâ”€â”€ app.py
â””â”€â”€ Dockerfile"""
"

" 